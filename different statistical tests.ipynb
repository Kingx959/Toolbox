{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae9f1ee",
   "metadata": {},
   "source": [
    "# independent 2 sample T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefe57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Read CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Assuming your CSV has columns 'sample' and 'values'\n",
    "sample1 = data[data['sample'] == 'Sample 1']['values']\n",
    "sample2 = data[data['sample'] == 'Sample 2']['values']\n",
    "\n",
    "# Perform the independent t-test\n",
    "t_statistic, p_value = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the p-value is less than the significance level (e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235db382",
   "metadata": {},
   "source": [
    "# paired 2 sample T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e7b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Read CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Assuming your CSV has columns 'before' and 'after'\n",
    "before = data['before']\n",
    "after = data['after']\n",
    "\n",
    "# Perform the paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(before, after)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the p-value is less than the significance level (e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the paired samples.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the paired samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868db04",
   "metadata": {},
   "source": [
    "# one-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746dd003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 135.07762424279912\n",
      "P-Value: 3.319503795619655e-36\n",
      "Reject the null hypothesis: There is a significant difference among the groups.\n"
     ]
    }
   ],
   "source": [
    "#example using wine.csv\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Read CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('wine.csv')\n",
    "\n",
    "# Assuming your CSV has columns 'group' and 'values'\n",
    "groups = data['Wine']\n",
    "values = data['Alcohol']\n",
    "\n",
    "# Create separate data arrays for each group\n",
    "group_dict = {}\n",
    "for group_id, value in zip(groups, values):\n",
    "    if group_id not in group_dict:\n",
    "        group_dict[group_id] = []\n",
    "    group_dict[group_id].append(value)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(*group_dict.values())\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the p-value is less than the significance level (e.g., 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference among the groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference among the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a89ad8",
   "metadata": {},
   "source": [
    "# two way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Read CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Create an ordinary least squares (OLS) model\n",
    "model = ols('score ~ C(group) + C(gender) + C(group):C(gender)', data=data).fit()\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209a7fb",
   "metadata": {},
   "source": [
    "# MANCOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is alot like two way anova but taking it a step further.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# Read data into a pandas DataFrame\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Define independent variable, method A,B,C\n",
    "teaching_method = data['Teaching Method']\n",
    "\n",
    "# Define dependent variables\n",
    "dependent_vars = data[['Math', 'Science', 'English']]\n",
    "\n",
    "# Perform MANOVA\n",
    "manova = MANOVA(dependent_vars, teaching_method)\n",
    "\n",
    "# Print the results\n",
    "print(manova.mv_test())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aec50e",
   "metadata": {},
   "source": [
    "# ANCOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd98d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Read CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Define independent variable (categorical) and covariate (continuous)\n",
    "group = data['group']\n",
    "covariate = data['age']\n",
    "\n",
    "# Define dependent variables (pretest and posttest)\n",
    "pretest = data['pretest']\n",
    "posttest = data['posttest']\n",
    "\n",
    "# Fit the ANCOVA model\n",
    "covariate = sm.add_constant(covariate)  # Add a constant term for the intercept\n",
    "model = sm.OLS(posttest, pretest).fit(cov_type='HC3', cov_kwds={'groups': group, 'time': 'group'})\n",
    "\n",
    "# Perform the ANCOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANCOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4acce8",
   "metadata": {},
   "source": [
    "## uses 'counter' to test for balance/imbalance in data if ratio >2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e86c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'creditcard.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming you have a binary target column named 'target_column_name'\n",
    "target_column_name = 'Class'  # Replace with your actual target column name\n",
    "\n",
    "# Check the class distribution\n",
    "class_distribution = Counter(df[target_column_name])\n",
    "\n",
    "# Print the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# Calculate the imbalance ratio\n",
    "if len(class_distribution) == 2:\n",
    "    minority_class = min(class_distribution, key=class_distribution.get)\n",
    "    majority_class = max(class_distribution, key=class_distribution.get)\n",
    "    minority_class_count = class_distribution[minority_class]\n",
    "    majority_class_count = class_distribution[majority_class]\n",
    "\n",
    "    imbalance_ratio = majority_class_count / minority_class_count\n",
    "\n",
    "    print(f\"Imbalance Ratio: {imbalance_ratio:.2f}\")\n",
    "    if imbalance_ratio > 2:  # You can adjust this threshold based on your problem\n",
    "        print(\"The dataset is imbalanced.\")\n",
    "    else:\n",
    "        print(\"The dataset is not significantly imbalanced.\")\n",
    "else:\n",
    "    print(\"The dataset should have exactly two classes for binary classification.\")\n",
    "\n",
    "# Optionally, you can visualize the class distribution or take further actions to handle imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc02fb",
   "metadata": {},
   "source": [
    "## Synthetic minority oversampling technique SMOTE then RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = 'your_dataset.csv'  # Replace with the path to your CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming you have a target column named 'target_column_name'\n",
    "target_column_name = 'target'  # Replace with your actual target column name\n",
    "\n",
    "# Separate features (X) and the target (y)\n",
    "X = df.drop(columns=[target_column_name])\n",
    "y = df[target_column_name]\n",
    "\n",
    "# Apply SMOTE to balance the data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e26bbd-8663-46b3-8ccb-06e36687a2d3",
   "metadata": {},
   "source": [
    "### Anderson-Darling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41322da-c3a9-40d5-8a8e-3ded2ab707a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import anderson\n",
    "\n",
    "# Read in the CSV file (replace 'your_data.csv' with the actual file path)\n",
    "data = pd.read_csv('ADNI1_3T_ROI.csv')\n",
    "\n",
    "# Loop through columns and perform Anderson-Darling test\n",
    "for column in data.columns:\n",
    "    sample_data = data[column]\n",
    "    result = anderson(sample_data)   # or result=anderson(sample_data, dist='choose') {‘norm’, ‘expon’, ‘logistic’, ‘gumbel’, ‘gumbel_l’, ‘gumbel_r’, ‘extreme1’, ‘weibull_min’}\n",
    "    \n",
    "    # Extract the test statistic and critical values\n",
    "    test_statistic = result.statistic\n",
    "    critical_values = result.critical_values\n",
    "\n",
    "    # Interpret the results\n",
    "    print(f'Anderson-Darling Test for \"{column}\"')\n",
    "    print(f'Test Statistic: {test_statistic}')\n",
    "    print('Critical Values:')\n",
    "    for i in range(len(critical_values)):\n",
    "        significance_level = [15, 10, 5, 2.5, 1][i]\n",
    "        is_significant = test_statistic > critical_values[i]\n",
    "        print(f'Significance Level {significance_level}%: Test {\"significant\" if is_significant else \"not significant\"}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
